{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgv2cUHd5/JvmrYOMI0x9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsh0137/GAN/blob/main/DCGAN_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ8p69A7PoJF"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJe6btghP9Wq"
      },
      "source": [
        "img_rows = 28\n",
        "img_cols = 288\n",
        "channels = 1\n",
        "\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "z_dim = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoDzGJ48QFem"
      },
      "source": [
        "def build_generator(z_dim):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(256 * 7 * 7, input_dim=z_dim)) # 완전 연결 층을 사용해 입력을 7 X 7 X 256 크기 텐서로 바꿉니다.\n",
        "  model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "  model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')) # 7 X 7 X 256에서 14 X 14 X 128 크기 텐서로 바꾸는 전치 합성곱 층\n",
        "  model.add(BatchNormalization()) # 배치 정규화\n",
        "  \n",
        "  model.add(LeakyReLU(alpha=0.01)) # LeakyReLU 활성화 함수\n",
        "\n",
        "  model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) # 14X14X128에서 14X14X64 크기 텐서로 바꾸는 전치 합성곱 층\n",
        "\n",
        "  model.add(BatchNormalization()) # 배치 정규화\n",
        "\n",
        "  model.add(LeakyReLU(alpha=0.01)) # LeakyReLU 활성화 함수\n",
        "\n",
        "  model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same')) # 14 X 14 X 64에서 28 X 28 X 1 크기 텐서로 바꾸는 전치 합성곱 층\n",
        "\n",
        "  model.add(Activation('tanh')) # tanh 활성화 함수를 사용하는 출력층\n",
        "\n",
        "  return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgmP8mUdUDMK"
      },
      "source": [
        "def build discriminator(img_shape):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same')) # 28X28X1 텐서에서 14X14X32크기 텐서로 바꾸는 합성곱 층\n",
        "\n",
        "  model.add(LeakyReLU(alpha=0.01)) # LeakyReLU 활성화 함숫\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "\n",
        "  model.add(LeakyReLU(alpha=0.01)) # LeakyReLU 활성화 함수.\n",
        "\n",
        "  model.add(Flatten()) # Sigmoid 활성화 함수를 위한 Flatten\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}